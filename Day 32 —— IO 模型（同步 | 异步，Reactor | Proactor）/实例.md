本节目标：  
**从工程行为出发，理解同步 / 异步 IO 以及 Reactor / Proactor 是如何影响系统结构的。**

---

## 一、为什么工程中必须明确 IO 模型？

在真实系统中：

* IO 等待时间不可控
* 并发连接数量巨大

如果 IO 模型选择错误：

* 线程被大量阻塞
* 系统吞吐量迅速下降

因此：

> **IO 模型决定了系统的并发上限。**

---

## 二、同步 IO 在工程中的真实表现

### 典型场景

* 使用 epoll + 非阻塞 socket
* 事件就绪后由线程读取数据

此时：

* epoll 只负责“通知就绪”
* recv 仍由应用线程执行
* 数据拷贝发生在用户态与内核态之间

工程结论：

> **线程仍然要为 IO 操作付出执行时间。**

---

## 三、Reactor 在工程中的落地形态

在 Reactor 架构下：

* 主线程负责事件监听
* 工作线程负责 IO + 业务处理
* 每个事件对应一个 Handler

这种模式的优势是：

* 架构清晰
* 易于扩展
* 易于调试

这也是：

> **epoll + Reactor 成为主流 C++ 网络模型的原因。**

---

## 四、异步 IO 在工程中的真实表现

在异步 IO 场景下：

* 应用发起 IO 请求后立即返回
* 内核在后台完成 IO
* 完成后通过回调或事件通知应用

此时：

* 应用线程不再参与 IO 等待
* 只处理“完成事件”

---

## 五、Proactor 的工程特点

在 Proactor 模式中：

* 应用不再显式调用 recv / send
* 收到的是“IO 已完成”的事件
* 数据已经准备就绪

工程上的优势：

* 线程利用率高
* IO 与业务解耦彻底

但代价是：

> **实现复杂，对系统和库支持要求高。**

---

## 六、为什么 Linux 中 Reactor 更常见？

原因并不在设计理念，而在现实条件：

* Linux 原生异步 IO 支持有限
* epoll 本质是 IO 就绪通知
* 用户态仍需执行 IO 操作

因此：

> **Linux C++ 高性能网络库，几乎都基于 Reactor。**

---

## 七、工程级总结

> 同步 IO + Reactor 追求的是“可控与稳定”，  
> 异步 IO + Proactor 追求的是“极致并发与解耦”。  

选择哪一种，  
取决于系统复杂度和维护成本。
